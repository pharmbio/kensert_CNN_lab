{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of cell morphological changes with Neural Networks\n",
    "_by Alexander Kensert, June 2018_\n",
    "#### Inspired by\n",
    "This step by step exercise is highly inspired by the Andrew Ng's **Deep learning** Coursera specialization [Link](https://www.coursera.org/specializations/deep-learning). This step by step exercise will take you through a machine learning workflow which includes reading dataset, create and compile model, train model on dataset, and predict on test set (to evaluate your model). \n",
    "\n",
    "#### Datasets\n",
    "The specific dataset used for this lab will be a subset of the bbbc021v1 dataset [Link](http://mct.aacrjournals.org/content/9/6/1913) (Caie et al., 2010), available from the Broad Bioimage Benchmark Collection [Link](https://www.nature.com/articles/nmeth.2083) (Ljosa et al., 2012).\n",
    "\n",
    "#### Importance\n",
    "After you've completed this lab, you will know how to develop and utilize advanced machine learning models (in this case a Neural Network on high content cell images). This approach of classyfing biological cell-images could still be considered very modern --- where traditional approaches of complex workflows, where each step of the analysis require manual implementation, still dominates. However, this approach (utilizing Neural networks) are very promising due to the much better hardware available today, with the capability to perform equal or better than the traditional techniques based on merely the pixel-intensities of the images!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np                   # For working with arrays (\"a package for scientific computing with Python\")\n",
    "import pandas as pd                  # For reading csv file\n",
    "import tensorflow as tf              # TensorFlow\n",
    "import matplotlib.pyplot as plt      # For plotting\n",
    "from nn_utils import *               # Import helper functions; look inside nn_utils.py for more info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_orig, Y_orig = load_dataset()\n",
    "\n",
    "print(\"Shape of X_orig = \" + str(X_orig.shape))\n",
    "print(\"Shape of Y_orig = \" + str(Y_orig.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Map X to a 0-1 range; and convert Y to one hot encoding (by using the nn_utils function convert_to_one_hot)\n",
    "X = X_orig/255.\n",
    "Y = convert_to_one_hot(Y_orig, 6)\n",
    "\n",
    "print(\"Shape of X = \" + str(X.shape))\n",
    "print(\"Shape of Y = \" + str(Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide dataset into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(10) # Random seed is used throughout this lab to keep the results consistent.\n",
    "\n",
    "indices = np.random.permutation(X.shape[0])\n",
    "train_idx, test_idx = indices[:500], indices[500:]\n",
    "X_train, X_test, Y_train, Y_test = X[train_idx, :, :, :], X[test_idx, :, :, :], Y[train_idx, :], Y[test_idx, :]\n",
    "\n",
    "print(\"Shape of X train = \" + str(X_train.shape))\n",
    "print(\"Shape of Y train = \" + str(Y_train.shape))\n",
    "print(\"Shape of X test  = \" + str(X_test.shape))\n",
    "print(\"Shape of Y test  = \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illustrate input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run cell to plot few example images of the training set\n",
    "fig=plt.figure(figsize=(14, 10))\n",
    "fig.suptitle(\"Examples of training images\", fontsize=20)\n",
    "columns = 3\n",
    "rows = 2\n",
    "for i in range(1, columns*rows +1):\n",
    "    idx = np.where(np.argmax(Y_train, axis=1) == i-1)[0]\n",
    "    img = (X_train[idx[2]]*255).astype(\"uint8\")\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.axis('off')\n",
    "    plt.title(Y_orig[train_idx][idx[2]], fontsize=14)\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Convolutional Neural Network with Tensorflow\n",
    "\n",
    "**In this lab** you will learn how to implement your own convolutional neural network for classifying cell phenotypes. And you will be using the open-source machine learning framework **TensorFlow** to do so (https://www.tensorflow.org). TensorFlow was developed by the **Google Brain** team and is today one of the most widely used machine learning framework in research and industry. \n",
    "\n",
    "Convolutional Neural Networks (CNNs) use convolutions instead of the normal fully connected layers, which have proven to be highly successful for image recognition tasks. By convolving **filters** on the input layer and output it to the next layer, the CNN learns to \"detect\" (or learn) features of the different levels of abstractions throughout the network. With lower-level abstractions (like edges and blobs) in the early layers, and higher-level abstractions (like animal faces) in deeper layers. Figure 1 shows a CNN with 3 convolutional layers, 3 max pooling layers, and two final fully connected layers.\n",
    "\n",
    "<p>\n",
    "    <img src=\"pictures/conv.png\" alt=\"drawing\" style=\"width:1200px;\"/>\n",
    "    <center>Figure 1. A simple illustration of the convolutional neural network that you will implement in section 1.</center>\n",
    "</p>\n",
    "\n",
    "\n",
    "**If you're getting stuck** or stumble upon problems, don't hesitate to use Google or similar to search for answers. There are plenty of information out there regarding TensorFlow implementations. It is also very useful to read about the different TensorFlow functions on their website. Also, make use of the lecture notes and try to think carefully about what you're actually implementing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Create placeholders\n",
    "\n",
    "Placeholders could be said to be variables that can be fed data later (when we run the session). It allows us to create our operations and build our computation graph without needing the data doing so. \n",
    "\n",
    "**Exercise**: Implement a function to create placeholders for input X and output Y [Hint](https://www.tensorflow.org/api_docs/python/tf/placeholder). Input X is the images, and output Y their labels; hence placeholder for input X should have dimension **[None, n_H0, n_W0, n_C0]** and placeholder for output Y dimension **[None, n_y]**. \"None\" allows for more flexibility, we don't need to specify the number of images that will be fed to the network later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
    "    \"\"\"\n",
    "    arguments: \n",
    "        n_H0 -- height of the image\n",
    "        n_W0 -- width of the image\n",
    "        n_C0 -- number of channels of the image\n",
    "        n_y  -- number of classes\n",
    "        \n",
    "    returns:\n",
    "        X -- placeholder for the data input, of shape (None, n_H0, n_W0, n_C0) and dtype \"float\"\n",
    "        Y -- placeholder for the input labels, of shape (None, n_y) and dtype \"float\"\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    ###--- Start your code here ---### (2 lines of code)\n",
    "    X = None\n",
    "    Y = None\n",
    "    ###--- End your code here ---###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell to test your function\n",
    "X, Y = create_placeholders(256, 256, 3, 6)\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "\n",
    "<table> \n",
    "<tr>\n",
    "<td>\n",
    "    X = Tensor(\"Placeholder:0\", shape=(?, 256, 256, 3), dtype=float32)\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "    Y = Tensor(\"Placeholder_1:0\", shape=(?, 6), dtype=float32)\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Initialize parameters\n",
    "\n",
    "In this section you will initialize the **weights** parameters. The bias parameters are taken care of by TensorFlow. These weights (and biases) are trainable parameters, and will later on be updated with gradient descent methods. \n",
    "\n",
    "**Exercise:** Implement initialize_parameters() function with tf.contrib.layers.xavier_initializer(seed = 10). \n",
    "\n",
    "**Hint:**\n",
    "```python \n",
    "W = tf.get_variable(name=\"W\", shape=[...], initializer = ...) \n",
    "```\n",
    "Initialize $W1$, $W2$ and $W3$, with shapes of [5,5,3,16], [5,5,16,32], [5,5,32,64] respectively. The first two numbers in each \"list\" are the shape of the filters (5x5) and the third number is the number of input channels, and the forth number is the chosen number of output channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    returns a dictionary with the tensors W1, W2, W3.\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(10)\n",
    "    \n",
    "    ###--- Start your code here ---### (3 lines of code)\n",
    "    W1 = None\n",
    "    W2 = None\n",
    "    W3 = None\n",
    "    ###--- Start your code here ---###\n",
    "    \n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2,\n",
    "                  \"W3\": W3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell to test your function\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess_test:\n",
    "    parameters = initialize_parameters()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess_test.run(init)\n",
    "    print(\"W1 = \" + str(parameters[\"W1\"].eval()[1,1,1][:10]))\n",
    "    print(\"W2 = \" + str(parameters[\"W2\"].eval()[1,1,1][:10]))\n",
    "    print(\"W3 = \" + str(parameters[\"W3\"].eval()[1,1,1][:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "\n",
    "<table> \n",
    "    <tr>\n",
    "        <td>\n",
    "        W1 = \n",
    "        </td>\n",
    "        <td>\n",
    "[-0.02518947  0.08526616  0.01068459 -0.10064837  0.04996547  0.00771768\n",
    "  0.06277266 -0.08534607 -0.10441076 -0.09985781]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "        W2 = \n",
    "        </td>\n",
    "        <td>\n",
    "[-0.01720679  0.00607508  0.02880752  0.00570655  0.03972469  0.02047629\n",
    " -0.0242044  -0.0558014  -0.06790373 -0.04631682]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <td>\n",
    "        W3 = \n",
    "        </td>\n",
    "        <td>\n",
    "[-0.01969862 -0.02796849  0.02530041  0.01744844 -0.04213814 -0.03856876\n",
    "  0.02646131 -0.0229876  -0.02251153 -0.04183786]\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Forward propagation\n",
    "\n",
    "In this section you will implement the forward propagation of the network. The forward propagation is needed to feedforward the input data through the network to obtain an output (a training data prediction). This output is then \"compared\" with the ground truth label (the actual label of the input data) through a Cost function (see next section). The network then propagates backward (a.k.a. back-propagation) based on this Cost function, and updates the weights (from section 1.2) and biases before next iteration. You will later see that Tensorflow allows you to very easily implement the back-propagation with one-line of code (an otherwise complicated implementation).\n",
    "\n",
    "**Exercise:** Implement the forward_propagation() function to build your model. Model architecture:<br/> \n",
    "CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED -> <br/>\n",
    "-> ReLU -> FULLYCONNECTED <br/>\n",
    "\n",
    "\n",
    "In detail, you will follow the following steps:\n",
    "     - Conv2D: stride 2, padding is \"SAME\"\n",
    "     - ReLU\n",
    "     - Max pool: Use an 2 by 2 filter size and an 2 by 2 stride, padding is \"SAME\"\n",
    "     - Conv2D: stride 1, padding is \"SAME\"\n",
    "     - ReLU\n",
    "     - Max pool: Use a 4 by 4 filter size and a 4 by 4 stride, padding is \"SAME\"\n",
    "     - Conv2D: stride 1, padding is \"SAME\"\n",
    "     - ReLU\n",
    "     - Max pool: Use a 4 by 4 filter size and a 4 by 4 stride, padding is \"SAME\"\n",
    "     - Flatten the previous output.\n",
    "     - FULLYCONNECTED (FC): Use 1024 nodes and kernel_initializer=tf.contrib.layers.xavier_initializer(seed=10)\n",
    "     - ReLU\n",
    "     - FULLYCONNECTED (FC) layer: Apply a fully connected layer without a non-linear activation function. \n",
    "     The softmax function will be called later together with the cost function (they are lumped together as \n",
    "     you will see later). Use 6 nodes and kernel_initializer=tf.contrib.layers.xavier_initializer(seed=10)\n",
    "     \n",
    "**Hints:** For conv2d use [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d); for relu use [tf.nn.relu](https://www.tensorflow.org/api_docs/python/tf/nn/relu); for max pooling use [tf.nn.max_pool](https://www.tensorflow.org/api_docs/python/tf/nn/max_pool); for flatten use [tf.contrib.layers.flatten](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/flatten); and finally for FC use [tf.layers.dense](https://www.tensorflow.org/api_docs/python/tf/layers/dense)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    -> ReLU -> FULLYCONNECTED\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder: shape (m, height, width, channels)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"W2\" and \"W3\".\n",
    "\n",
    "    Returns:\n",
    "    Z5 -- the output of the last linear unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    W3 = parameters['W3']\n",
    "    \n",
    "    ###--- START YOUR CODE HERE ---### \n",
    "    # CONV2D: stride of 1, padding 'SAME'\n",
    "    Z1 = None\n",
    "    # RELU\n",
    "    A1 = None\n",
    "    # MAXPOOL: window 4x4, sride 4, padding 'SAME'\n",
    "    P1 = None\n",
    "    # CONV2D: filters W2, stride 1, padding 'SAME'\n",
    "    Z2 = None\n",
    "    # RELU\n",
    "    A2 = None\n",
    "    # MAXPOOL: window 4x4, stride 4, padding 'SAME'\n",
    "    P2 = None\n",
    "    # CONV2D: filters W3, stride 1, padding 'SAME'\n",
    "    Z3 = None\n",
    "    # RELU\n",
    "    A3 = None\n",
    "    # MAXPOOL: window 4x4, stride 4, padding 'SAME'\n",
    "    P3 = None\n",
    "    # FLATTEN\n",
    "    P3 = None\n",
    "    \n",
    "    # Dense layer\n",
    "    Z4 = None\n",
    "    # Relu\n",
    "    A4 = None\n",
    "    # FULLY-CONNECTED without non-linear activation function.\n",
    "    # 6 neurons in output layer. Hint: one of the arguments should be \"activation_fn=None\" \n",
    "    Z5 = None\n",
    "    ###--- END YOUR CODE HERE ---###\n",
    "\n",
    "    return Z5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell to test your function\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(10)\n",
    "    X, Y = create_placeholders(256, 256, 3, 6)\n",
    "    parameters = initialize_parameters()\n",
    "    Z5 = forward_propagation(X, parameters)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    a = sess.run(Z5, {X: np.random.randn(2,256,256,3), Y: np.random.randn(2,6)})\n",
    "    print(\"Z5 = \" + str(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "\n",
    "<table> \n",
    "<tr>\n",
    "<td>\n",
    "    Z5 = [[ 0.21268588  0.5898833  -0.1474437  -0.12360391 -0.22346927 -0.7871422 ]<br>\n",
    " [ 0.21345036  0.5388961  -0.11780731 -0.12841246 -0.16621907 -0.7878238 ]]\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 GPU implementation\n",
    "\n",
    "If you have a GPU available, you should later on use the below function. `forward_propagation_gpu()` is exactly the same as `forward_propagation()` but ran on a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation_gpu(X, parameters, gpu):\n",
    "    with tf.device('/gpu:'+str(gpu)):\n",
    "        return forward_propagation(X, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Compute cost\n",
    "\n",
    "Implement the compute cost function below. With the cost we want to average the losses over all examples (input) to get an _overall cost_. This could be done in tensorflow by first computing the softmax entropy loss [Link 1](https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits_v2) (which computes the softmax activation function as well as the resulting loss), and then compute the mean of the elements [Link 2](https://www.tensorflow.org/api_docs/python/tf/reduce_mean).\n",
    "\n",
    "**Hints:** Make use of the Link 1 and Link 2 from above: \n",
    "- **tf.nn.softmax_cross_entropy_with_logits_v2(logits = Z5, labels = Y)**\n",
    "- **tf.reduce_mean()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(Z5, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    ###--- START CODE HERE ---### (1 line of code)\n",
    "    cost = None\n",
    "    ###--- END CODE HERE ---###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell to test your function\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(10)\n",
    "    X, Y = create_placeholders(256, 256, 3, 6)\n",
    "    parameters = initialize_parameters()\n",
    "    Z4 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z4, Y)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    a = sess.run(cost, {X: np.random.randn(4,256,256,3), Y: np.random.randn(4,6)})\n",
    "    print(\"cost = \" + str(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "\n",
    "<table>\n",
    "    <td> \n",
    "    cost =\n",
    "    </td> \n",
    "    \n",
    "    <td> \n",
    "    2.6181931\n",
    "    </td> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Finalize model\n",
    "\n",
    "In this last step, you will merge the helper functions that you've implemented above to build your model --- a model trained on high content cell images.\n",
    "\n",
    "The imported function `random_mini_batches()` will be used to obtain mini-batches. In each for loop a new mini-batch of two lists (minibatch_X and minibatch_Y) will be obtained, which is then fed to the feed_dict.\n",
    "\n",
    "**Exercise**: Complete the function below. \n",
    "\n",
    "The model below should:\n",
    "\n",
    "- create placeholders\n",
    "- initialize parameters\n",
    "- forward propagate\n",
    "- compute the cost\n",
    "- optimize\n",
    "\n",
    "Finally you will create a session, and run the session with `sess.run()` [Link](https://www.tensorflow.org/api_docs/python/tf/Session) (which is inside the for loops num_epochs and minibatches). Thus for each mini-batch you will optimize the function.\n",
    "\n",
    "**Hints:**<br/> \n",
    "For creating the optimizer: `tf.train.AdamOptimizer(learning_rate=...)` and method `minimize(cost)`.<br/>\n",
    "For running the session: `sess.run([optimizer, cost], feed_dict={X: ..., Y: ...})`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, \n",
    "          learning_rate = 0.01, num_epochs = 20, minibatch_size = 32):\n",
    "    \"\"\"\n",
    "    Implements a three-layer ConvNet in Tensorflow:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, shape (None, 256, 256, 3)\n",
    "    Y_train -- test set, shape (None, n_y = 6)\n",
    "    X_test -- training set, shape (None, 256, 256, 3)\n",
    "    Y_test -- test set, shape (None, n_y = 6)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of the minibatch\n",
    "    \n",
    "    Returns:\n",
    "    train_accuracy -- real number, accuracy on the train set (X_train)\n",
    "    test_accuracy -- real number, testing accuracy on the test set (X_test)\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.reset_default_graph()                          \n",
    "    tf.set_random_seed(10)                            # to keep results consistent (tensorflow seed)\n",
    "    seed = 10                                         # to keep results consistent (numpy seed)\n",
    "    (m, n_H0, n_W0, n_C0) = X_train.shape             \n",
    "    n_y = Y_train.shape[1]                            \n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    ###--- START YOUR CODE HERE ---###\n",
    "    \n",
    "    # I. Create Placeholders of the correct shape\n",
    "    X, Y = None\n",
    "    \n",
    "    # II. Initialize parameters\n",
    "    parameters = None\n",
    "    \n",
    "    # III. Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    # Use forward_propagation_gpu(X, parameters, gpu=...) if GPU is available; \n",
    "    # Specify which GPU to use by inputting an integer between 0-9 in gpu=... argument.\n",
    "    Z5 = None\n",
    "    \n",
    "    # IV. Cost function: Add cost function to tensorflow graph\n",
    "    cost = None\n",
    "    \n",
    "    # V. Backpropagation: Define the tensorflow optimizer. Use a AdamOptimizer that minimizes the cost.\n",
    "    optimizer = None\n",
    "    \n",
    "    ###--- END YOUR CODE HERE ---###\n",
    "    \n",
    "    # Initialize all the variables globally\n",
    "    init = tf.global_variables_initializer()\n",
    "     \n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            minibatch_cost = 0.\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).\n",
    "                ###--- START YOUR CODE HERE ---### (1 line of code)\n",
    "                # VI. Run session\n",
    "                _ , temp_cost = None\n",
    "                ###--- END YOUR CODE HERE ---###\n",
    "                \n",
    "                minibatch_cost += temp_cost / num_minibatches\n",
    "            \n",
    "            # Print the cost every epoch\n",
    "            if epoch % 1 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch+1, minibatch_cost))\n",
    "                costs.append(minibatch_cost)\n",
    "        \n",
    "        \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('Cost')\n",
    "        plt.xlabel('Number of epochs')\n",
    "        plt.title(\"Learning rate = \" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        predict_op = tf.argmax(Z5, 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "        \n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "                \n",
    "        return train_accuracy, test_accuracy, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run cell to start training and make predictions\n",
    "_, _, parameters = model(X_train, Y_train, X_test, Y_test,\n",
    "                         learning_rate  = 0.001, \n",
    "                         num_epochs = 30, \n",
    "                         minibatch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training will take some time (~5-10 minutes) if you are running on **CPUs**. Before you go on a break, check that the cost is decreasing after the first few epochs. If you are fortunate and are running on a **GPU**, the training will be signficantly faster (~30-100 times faster).\n",
    "\n",
    "**Expected output**: your cost and accuracy should match with the below. Importantly, your cost should decrease. Test accuracy can vary quite a lot depending on which learning rate you use and how many epochs you are training; test accuracy is expected to range between 70-80% accuracy.\n",
    "\n",
    "<table> \n",
    "<tr>\n",
    "    <td> \n",
    "    **Cost after epoch 1 =**\n",
    "    </td>\n",
    "\n",
    "    <td> \n",
    "      1.683048\n",
    "    </td> \n",
    "</tr>\n",
    "<tr>\n",
    "    <td> \n",
    "    **Cost after epoch 2 =**\n",
    "    </td>\n",
    "\n",
    "    <td> \n",
    "      1.240209\n",
    "    </td> \n",
    "</tr>\n",
    "<tr>\n",
    "    <td> \n",
    "    **Train Accuracy   =**\n",
    "    </td>\n",
    "\n",
    "    <td> \n",
    "      1.0\n",
    "    </td> \n",
    "</tr> \n",
    "\n",
    "<tr>\n",
    "    <td> \n",
    "    **Test Accuracy   =**\n",
    "    </td>\n",
    "\n",
    "    <td> \n",
    "      0.7625\n",
    "    </td> \n",
    "</tr> \n",
    "</table>\n",
    "\n",
    "You obtained a 70%+ accuracy! Good work! Keep in mind that you could possibly improve this network even further by changing the hyperparameter settings and/or add regularization (weight decay or drop out) to the layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Deep residual CNN (~30 layers)\n",
    "In this section, the final part of this lab, you will implement a deeper state-of-the-art CNN. Specifically, the CNN that you will implement is not too different from the residual CNN presented by He _et al._ (see [article](https://arxiv.org/pdf/1512.03385.pdf)). \n",
    "\n",
    "A deep residual network contains dozens of residual blocks (see Figure 2) with intermediate normalization. The identity mapping is often called _skip-connection_ or _shortcut_ and has shown to assist in avoiding the degrading effect of training very deep networks --- a degrading effect that is most apparent for \"plain\" networks. Thus, the residual implementation made it possible to successfully train a very deep CNN that outperform all the other CNNs that came before.\n",
    "\n",
    "<p>\n",
    "    <img src=\"pictures/residual_block.png\" alt=\"drawing\" style=\"width:400px;\"/>\n",
    "    <center>Figure 2. A residual block - the building block of a residual network.</center>\n",
    "</p>\n",
    "\n",
    "\n",
    "In this section we do not need to implement **placeholders** or **cost function** because those can be reused. However, two new fundamental and important implementations will be needed: **batch normalization** and **residual block** (see figure above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Initialize variable\n",
    "\n",
    "The get_variable function could be seen as a replacement for the initialize_parameters function. This function returns a variable, like the variables inside initialize_parameters() from section 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell to define function get_variable().\n",
    "def get_variable(name, shape):\n",
    "    tf.set_random_seed(10)\n",
    "    return tf.get_variable(name=name, shape=shape, initializer = tf.contrib.layers.xavier_initializer(seed=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Batch-normalization\n",
    "\n",
    "Normalization of input could help in improving Neural Networks. The idea of batch-normalization is to take this normalization to the intermediate layers. Specifically, the batch-normalization normalizes the layer's output before going through the activation function. This should make the Neural Network more stable and faster at training.\n",
    "\n",
    "We have implemented the batch_norm function for you, but feel free to take a look at it and to read the documentation [Here](https://www.tensorflow.org/api_docs/python/tf/nn/batch_normalization). **mean** and **variance** are the mean and variance of the input Tensor, **offset** and **scale** are trainable parameters, and **variance_epsilon** is there to avoid division by 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell to define function batch_norm().\n",
    "def batch_norm(input_tensor):\n",
    "    \"\"\"\n",
    "    Batch normalization for a 4-D tensor\n",
    "    \"\"\"\n",
    "    filter_shape = input_tensor.get_shape().as_list()\n",
    "    mean, var = tf.nn.moments(input_tensor, axes=[0, 1, 2])\n",
    "    out_channels = filter_shape[3]\n",
    "    offset = tf.Variable(tf.zeros([out_channels]))\n",
    "    scale = tf.Variable(tf.ones([out_channels]))\n",
    "    batch_norm = tf.nn.batch_normalization(input_tensor, mean, var, offset, scale, variance_epsilon=0.00001)\n",
    "    return batch_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Residual block\n",
    "\n",
    "**Exercise:** Implement the function `residual_block()` below. In detail, you will do the following steps:<br/>\n",
    "     - Conv2D: stride = [1,stride,stride,1], shape=[3,3,n_C_input,n_C_output], and padding \"SAME\"\n",
    "     - Batch-normalization\n",
    "     - ReLU\n",
    "     - Conv2D: stride = [1,1,1,1], shape=[3,3,n_C_output,n_C_output], and padding \"SAME\"\n",
    "     - Batch-normalization\n",
    "     - ...\n",
    "     After you have implemented the above steps we have implemented the final mapping for you.\n",
    "**Hint** for implementing Conv2D:\n",
    "```python \n",
    "x = tf.nn.conv2d(tensor, \n",
    "                 get_variable(name=\"..\"+str(block+1)+\"..\", shape=[...]), \n",
    "                 strides=[...], \n",
    "                 padding=...)\n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residual_block(input_tensor, n_C_input, n_C_output, stride, block):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        input_tensor -- 4-D tensor\n",
    "        n_C_input   -- number of channels of input\n",
    "        n_C_output  -- number of channels of output\n",
    "        stride      -- size of strides \n",
    "        block       -- block number\n",
    "        \n",
    "    Returns:\n",
    "        Tensor -- a residual mapping\n",
    "        \n",
    "    \"\"\"\n",
    "    ###---START CODE HERE---###\n",
    "    \n",
    "    # first convolution layer\n",
    "    x = None\n",
    "    x = None\n",
    "    x = None\n",
    "    \n",
    "    # second convolution layer\n",
    "    x = None\n",
    "    x = None\n",
    "    \n",
    "    ###---END CODE HERE---###\n",
    "    \n",
    "    # Input shortcut is added to the stacked layers (shortcut + above; H(x) = x + F(x))\n",
    "    # Is either identity mapping or \n",
    "    # single conv2d layer mapping (to get the same dimensions as the output of the stacked layers)\n",
    "    if n_C_input != n_C_output:\n",
    "        conv = tf.nn.conv2d(input_tensor, \n",
    "                            get_variable(name=\"W\"+str(block+1)+\"_shortcut\", shape=[3,3,n_C_input,n_C_output]),\n",
    "                            strides=[1, stride, stride, 1], \n",
    "                            padding=\"SAME\")\n",
    "        conv = batch_norm(conv)\n",
    "        mapping = x + conv\n",
    "    \n",
    "    else:\n",
    "        identity = input_tensor\n",
    "        mapping  = x + identity\n",
    "    \n",
    "    mapping = tf.nn.relu(mapping)\n",
    "    \n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(10)\n",
    "    X, Y      = create_placeholders(256, 256, 3, 6)\n",
    "    x         = get_variable(name=\"x\", shape=[3,3,3,16])\n",
    "    mapping   = residual_block(x, 16, 16, 1, 1)\n",
    "    init      = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    a = sess.run(mapping, {X: np.random.randn(3,256,256,3), Y: np.random.randn(3,6)})\n",
    "    print(\"mapping = \" + str(a[:,:,:,0][0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "\n",
    "<table> \n",
    "<td>\n",
    "    mapping = [[0.        0.4889835 0.       ]<br>\n",
    "              [0.        1.0255224 0.       ]<br>\n",
    "              [1.2879109 2.4008121 0.       ]]\n",
    "\n",
    "</td>\n",
    "</table>\n",
    "\n",
    "**Note** that we're not using max pooling for this architecture. You will see that we're instead using strides of two to reduce the dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Resnet forward propagation\n",
    "\n",
    "**Exercise:** implement function forward_propagation_resnet. Add residual blocks until dimensions of x have been reduced to 4x4x3. Aim for a total of 14 blocks.\n",
    "\n",
    "**Hint 1:** for implementing the residual network do something like this:\n",
    "```python \n",
    "block1 = residual_block(P1,     n_C_input=32,  n_C_output=64,  stride=2, block=1)\n",
    "block2 = residual_block(block1, n_C_input=64,  n_C_output=64,  stride=1, block=1)\n",
    "block3 = residual_block(block2, n_C_input=64,  n_C_output=64,  stride=1, block=3)\n",
    "\n",
    "block4 = residual_block(block3, n_C_input=64,  n_C_output=128, stride=2, block=4)\n",
    "block5 = residual_block(block4, n_C_input=128, n_C_output=128, stride=1, block=5)\n",
    "...\n",
    "...\n",
    "...\n",
    "block14 = residual_block(block13, n_C_input=512, n_C_output=512, stride=1, block=14)\n",
    "```\n",
    "\n",
    "**Hint 2:** Input images are of dimensions 256x256x3. So after Z1 = ..., the dimensions have been reduced to 128x128x3 (due to strides = 2), and after P1 = ... reduced further to 64x64x3 (due to strides = 2). This means that everytime **stride = 2** is used, dimensions halves, so make sure you don't reduce the dimensions to less than 4x4x3. Also, stride of 2 doesn't mean that n_C is/has to be increased, we just happen to increase it at that same point as stride of 2 is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation_resnet(X):\n",
    "    W1 = get_variable(name=\"W1\", shape=[5,5,3,32])\n",
    "    Z1 = tf.nn.conv2d(X, W1, strides = [1,2,2,1], padding = 'SAME')\n",
    "    Z1 = batch_norm(Z1)\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    P1 = tf.nn.max_pool(A1, ksize = [1,3,3,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "    \n",
    "    ###---START CODE HERE---###\n",
    "    block1  = None\n",
    "    block2  = None\n",
    "    block3  = None\n",
    "    \n",
    "    block4  = None\n",
    "    block5  = None\n",
    "    block6  = None\n",
    "    block7  = None\n",
    "    \n",
    "    block8  = None\n",
    "    block9  = None\n",
    "    block10 = None\n",
    "    block11 = None\n",
    "    \n",
    "    block12 = None\n",
    "    block13 = None\n",
    "    block14 = None\n",
    "    \n",
    "    \n",
    "    ###---END YOUR CODE HERE---###\n",
    "    \n",
    "    # Takes the mean of each output channel\n",
    "    global_pool = tf.reduce_mean(block14, [1,2])\n",
    "    \n",
    "    # For this model, only one fully connected layer is used\n",
    "    final = tf.layers.dense(global_pool, 6, kernel_initializer=tf.contrib.layers.xavier_initializer(seed=10))\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell to test your function\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(10)\n",
    "    X, Y    = create_placeholders(256, 256, 3, 6)\n",
    "    Z       = forward_propagation_resnet(X)\n",
    "    init    = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    a = sess.run(Z, {X: np.random.randn(2,256,256,3), Y: np.random.randn(2,6)})\n",
    "    print(\"Z = \" + str(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "\n",
    "<table> \n",
    "<td>\n",
    "    Z = [[-0.9732146   1.3482124  -0.00801492 -3.1542833  -3.0310855   0.7205707 ]<br>\n",
    "         [-0.10025907  1.4672053  -0.08543551 -2.4549499  -2.73242    -0.37045878]]<br>\n",
    "</td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 GPU implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run cell to implement function\n",
    "def forward_propagation_resnet_gpu(X, gpu):\n",
    "    with tf.device('/gpu:'+str(gpu)):\n",
    "        return forward_propagation_resnet(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Finalize resnet model\n",
    "\n",
    "**Exercise:** Similar to **Finalize model** from section 1, merge the helper functions that you've implemented:<br/>\n",
    "\n",
    "- create placeholders\n",
    "- forward propagatation (important: use `forward_propagation_resnet(X)` and not `forward_propagation(X, parameters)`)\n",
    "- compute the cost\n",
    "- create an optimizer\n",
    "\n",
    "And then finally run the session with `sess.run()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resnet(X_train, Y_train, X_test, Y_test, \n",
    "          learning_rate = 0.01, num_epochs = 20, minibatch_size = 16):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X_train -- training set, shape (None, 256, 256, 3)\n",
    "    Y_train -- test set, shape (None, n_y = 6)\n",
    "    X_test -- training set, shape (None, 256, 256, 3)\n",
    "    Y_test -- test set, shape (None, n_y = 6)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of the minibatch\n",
    "    \n",
    "    Returns:\n",
    "    train_accuracy -- real number, accuracy on the train set (X_train)\n",
    "    test_accuracy -- real number, testing accuracy on the test set (X_test)\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.reset_default_graph()                          \n",
    "    tf.set_random_seed(10)                            # to keep results consistent (tensorflow seed)\n",
    "    seed = 10                                         # to keep results consistent (numpy seed)\n",
    "    (m, n_H0, n_W0, n_C0) = X_train.shape             \n",
    "    n_y = Y_train.shape[1]                            \n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    \n",
    "    ###--- START YOUR CODE HERE ---###\n",
    "    \n",
    "    # I. Create Placeholders of the correct shape\n",
    "    X, Y = None\n",
    "    \n",
    "    # II. Forward propagation: Build the forward propagation in the tensorflow graph \n",
    "    # forward_propagation_resnet_gpu() if GPU is available.\n",
    "    Z = None\n",
    "    \n",
    "    # III. Cost function: Add cost function to tensorflow graph\n",
    "    cost = None\n",
    "    \n",
    "    # IV. Backpropagation: Define the tensorflow optimizer. Use a MomentumOptimizer that minimizes the cost.\n",
    "    optimizer = None\n",
    "    \n",
    "    ###--- END YOUR CODE HERE ---###\n",
    "    \n",
    "    # Initialize all the variables globally\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            minibatch_cost = 0.\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).\n",
    "                ###--- START YOUR CODE HERE ---### (1 line of code)\n",
    "                # V. Run session\n",
    "                _ , temp_cost = None\n",
    "                ###--- END YOUR CODE HERE ---###\n",
    "                \n",
    "                minibatch_cost += temp_cost / num_minibatches\n",
    "            \n",
    "            # Print the cost every epoch\n",
    "            if epoch % 1 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch+1, minibatch_cost))\n",
    "                costs.append(minibatch_cost)\n",
    "        \n",
    "        \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('Cost')\n",
    "        plt.xlabel('Number of epochs')\n",
    "        plt.title(\"Learning rate = \" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        predict_op = tf.argmax(Z, 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "        \n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "                \n",
    "        return train_accuracy, test_accuracy, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_, _, parameters = resnet(X_train, Y_train, X_test, Y_test, \n",
    "                          learning_rate = 0.001, num_epochs = 10, minibatch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you are training a deep network like this on CPUs**, it will take quite some time. Hence, we only train for 10 epochs. Normally you would like to train the model for longer to possibly obtain a better model, but for the sake of this lab we limited number of epochs to 10 (which will take ~20 minutes with 4 CPUs).<br/> **If you happen to run on a GPU**, change to 30 epochs and wait approximately 1 minute!\n",
    "\n",
    "**Expected output**: although it may not match perfectly, your expected output should be similar to ours and your cost value should decrease. Test accuracy can again vary quite a lot, and is expected to range between 85-95%.\n",
    "\n",
    "<table> \n",
    "<tr>\n",
    "    <td> \n",
    "    **Cost after epoch 1 =**\n",
    "    </td>\n",
    "\n",
    "    <td> \n",
    "      3.061539\n",
    "    </td> \n",
    "</tr>\n",
    "<tr>\n",
    "    <td> \n",
    "    **Cost after epoch 2 =**\n",
    "    </td>\n",
    "\n",
    "    <td> \n",
    "      1.172959\n",
    "    </td> \n",
    "</tr>\n",
    "<tr>\n",
    "    <td> \n",
    "    **10 epochs: Train Accuracy   =**<br/>\n",
    "    **30 epochs: Train Accuracy   =**\n",
    "    </td>\n",
    "\n",
    "    <td> \n",
    "      0.884<br/>\n",
    "      0.98\n",
    "    </td> \n",
    "</tr> \n",
    "\n",
    "<tr>\n",
    "    <td> \n",
    "    **10 epochs: Test Accuracy   =**<br/>\n",
    "    **30 epochs: Test Accuracy   =**\n",
    "    </td>\n",
    "\n",
    "    <td> \n",
    "      0.84375<br/>\n",
    "      0.93125\n",
    "    </td> \n",
    "</tr> \n",
    "</table>\n",
    "\n",
    "After implementing a deeper network you attained an even better test set accuracy! Good work! And again, this network could possibly be improved even further by tuning the hyperparameters and/or add regularization. Another important idea with deep learning is that these algorithms usually need a lot of labelled data --- which is lacking for these types of images. To work around this problem, something called data augmentation is usually implemented --- and promising results have been reported on transfer learning where we can use pre-trained parameters from another task to our task, where, as mentioned in section 1, early layers usually learns lower-level abstractions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### What you have accomplished\n",
    "\n",
    "1. Define helper functions of a CNN model\n",
    "2. Put together/create the model\n",
    "3. Train and optimize the model\n",
    "4. Make prediction of new unseen data (test set) with the model\n",
    "\n",
    "The modelling steps done in this lab (above steps) can be succesfully applied to other classification tasks. For example different biological data or recognizing natural images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
